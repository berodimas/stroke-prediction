{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "env",
   "display_name": "env",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('healthcare-dataset-stroke-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.bmi.replace(to_replace=np.nan, value=data.bmi.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = list(data.columns)\n",
    "categorical_data_cols  = [column for column in all_columns if len(data[column].unique())<=5]\n",
    "continuous_data_cols  = [column for column in all_columns if column not in categorical_data_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "i = 1\n",
    "for column in categorical_data_cols[:-1]:\n",
    "    plt.subplot(4, 2, i)\n",
    "    sns.countplot(x = data[column], hue = data[\"stroke\"])\n",
    "    i+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "i = 1\n",
    "for column in categorical_data_cols[:-1]:\n",
    "    type_count = data.groupby(column)[\"stroke\"].sum()\n",
    "    plt.subplot(4, 2, i)\n",
    "    x = type_count.index\n",
    "    y = type_count.values\n",
    "    plt.barh(x, y)\n",
    "    plt.title(f\"{column} vs Stroke\")\n",
    "    for index, value in enumerate(y):\n",
    "        plt.text(value, index,\n",
    "                 value)\n",
    "    i+=1\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "i = 1\n",
    "for column in continuous_data_cols:\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.distplot(data[column])\n",
    "    i+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.pairplot(data[['gender','age','hypertension','heart_disease','avg_glucose_level','bmi','stroke']],hue='stroke',kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "stroke_count = data[\"stroke\"].value_counts()\n",
    "x = stroke_count.index\n",
    "y = stroke_count.values\n",
    "plt.barh(x,y)\n",
    "for index, value in enumerate(y):\n",
    "        plt.text(value, index,\n",
    "                 value)\n",
    "\n",
    "plt.title(f\"Stroke Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.heatmap(data.corr(method='pearson'), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['smoking_status']!='Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender\n",
    "le = LabelEncoder()\n",
    "le.fit(data.gender.drop_duplicates())\n",
    "data.gender = le.transform(data.gender)\n",
    "\n",
    "# residence type\n",
    "le.fit(data.Residence_type.drop_duplicates())\n",
    "data.Residence_type = le.transform(data.Residence_type)\n",
    "\n",
    "# ever married\n",
    "le.fit(data.ever_married.drop_duplicates())\n",
    "data.ever_married = le.transform(data.ever_married)\n",
    "\n",
    "# smoking status\n",
    "le.fit(data.smoking_status.drop_duplicates())\n",
    "data.smoking_status = le.transform(data.smoking_status)\n",
    "\n",
    "# work type\n",
    "le.fit(data.work_type.drop_duplicates())\n",
    "data.work_type = le.transform(data.work_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop([\"stroke\"] , axis = 1)\n",
    "y = data[\"stroke\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "x_smote, y_smote = smote.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_smote, y_smote, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(['Logistic Regression', LogisticRegression(random_state = 0)])\n",
    "models.append(['Support Vector Machine (RBF Classifier)', SVC(kernel = 'rbf', random_state = 0)])\n",
    "models.append(['XGBClassifier', XGBClassifier(disable_default_eval_metric = True, random_state = 0)])\n",
    "models.append(['RandomForest', RandomForestClassifier(random_state = 0)])\n",
    "models.append(['AdaBoostClassifier', AdaBoostClassifier(base_estimator = models[3][1], random_state = 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = []\n",
    "for i in range(len(models)):\n",
    "    arr2 = []\n",
    "    model = models[i][1]\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    train_accuracies = model.score(x_train, y_train) * 100\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cr = classification_report(y_test, y_pred)\n",
    "    accuracies = cross_val_score(estimator = model, X = x_train , y = y_train, cv = KFold(n_splits=10, random_state=2020,\n",
    "                                shuffle=True), scoring = \"accuracy\")\n",
    "    kfold = accuracies.mean()*100\n",
    "    stdd = accuracies.std()*100\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    print(models[i][0] + \" Reports:\")\n",
    "    print(\"Training Accuracy: {}\".format(train_accuracies))\n",
    "    print(cm)\n",
    "    print(cr)\n",
    "    print('K-Fold Validation Mean Accuracy: {}'.format(kfold))\n",
    "    print('Standard Deviation: {}'.format(stdd))\n",
    "    print('ROC AUC Score: {}'.format(roc_auc))\n",
    "    print(\"---\"*20)\n",
    "    arr2.extend([models[i][0], kfold, stdd, roc_auc])\n",
    "    arr1.append(arr2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(arr1 , columns = ['Model','K-Fold Mean Accuracy','Std.Deviation','ROC_AUC'])\n",
    "\n",
    "df2.sort_values(by = [\"ROC_AUC\"] , inplace = True , ascending = False)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = \"ROC_AUC\" , y = \"Model\" , data = df2)\n",
    "plt.title(\"Model Compare\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[2][1]\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_\n",
    "print(feature_importance)\n",
    "\n",
    "feat_importances = pd.Series(feature_importance, index=data.drop([\"stroke\"] , axis = 1).columns)\n",
    "feat_importances = feat_importances.nlargest(10)\n",
    "feat_importances.plot(kind='barh' , figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([[1, 22.0, 1, 1, 1, 0, 0, 200.0, 30.0, 0]])\n",
    "predict = model.predict(values)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}